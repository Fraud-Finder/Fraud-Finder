# -*- coding: utf-8 -*-
"""XAI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NpwrmmZbz7mSP5E-jike-wuhM1v9QoKz
"""

# STEP 1: Install required packages
!pip install shap gcsfs xgboost

# STEP 2: Authenticate with Google if needed
from google.colab import auth
auth.authenticate_user()

# STEP 3: Set paths to your files in Google Cloud Storage
model_path = 'gs://ai_ops_final_project25k/pipeline_root/256797333550/credit-card-fraud-ml-pipeline-20250406030500/train-xgboost-model_-4596477814110158848/model_output/model.pkl'
test_data_path = 'gs://ai_ops_final_project25k/pipeline_root/256797333550/credit-card-fraud-ml-pipeline-20250405184331/split-data_-1865480046714552320/test_data.csv'

# STEP 4: Load the test dataset
import pandas as pd

X_test = pd.read_csv(test_data_path)

# Drop label column if it's included
if 'Class' in X_test.columns:
    X_test = X_test.drop(columns=['Class'])
print(X_test)

# STEP 5: Load the trained model from GCS
import gcsfs
import pickle

fs = gcsfs.GCSFileSystem()

with fs.open(model_path, 'rb') as f:
    model = pickle.load(f)

# STEP 6: Run SHAP to explain the model
import shap

explainer = shap.Explainer(model)
shap_values = explainer(X_test)

# STEP 7: Global explanation (most important features)
shap.summary_plot(shap_values, X_test, max_display=35)

# STEP 8: Local explanation for one example (e.g., row 0)
shap.plots.waterfall(shap_values[100])  # use another row with a clearer split

shap.plots.scatter(shap_values[:, "hour"], color=shap_values)